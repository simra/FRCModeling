{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023 TBA Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match data is fetched from TBA by running fetchMatches.py.  Run this first before running this notebook.\n",
    "\n",
    "`python fetchMatches.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching event 2023alhu\n",
      "Fetching event 2023arli\n",
      "Fetching event 2023ausc\n",
      "Fetching event 2023azgl\n",
      "Fetching event 2023azva\n",
      "Fetching event 2023bcvi\n",
      "Fetching event 2023brbr\n",
      "Fetching event 2023caav\n",
      "Fetching event 2023cada\n",
      "Fetching event 2023cafr\n",
      "Fetching event 2023cala\n",
      "Fetching event 2023camb\n",
      "Fetching event 2023caoc\n",
      "Fetching event 2023caph\n",
      "Fetching event 2023casd\n",
      "Fetching event 2023casf\n",
      "Fetching event 2023casj\n",
      "Fetching event 2023cave\n",
      "Fetching event 2023cc\n",
      "Fetching event 2023chcmp\n",
      "Fetching event 2023cmptx\n",
      "Fetching event 2023code\n",
      "Fetching event 2023cops\n",
      "Fetching event 2023cthar\n",
      "Fetching event 2023ctwat\n",
      "Fetching event 2023flor\n",
      "Fetching event 2023flta\n",
      "Fetching event 2023flwp\n",
      "Fetching event 2023gaalb\n",
      "Fetching event 2023gacar\n",
      "Fetching event 2023gacmp\n",
      "Fetching event 2023gadal\n",
      "Fetching event 2023gagwi\n",
      "Fetching event 2023gamac\n",
      "Fetching event 2023hiho\n",
      "Fetching event 2023iacf\n",
      "Fetching event 2023idbo\n",
      "Fetching event 2023ilch\n",
      "Fetching event 2023ilpe\n",
      "Fetching event 2023ilwz\n",
      "Fetching event 2023incmp\n",
      "Fetching event 2023ingre\n",
      "Fetching event 2023inmis\n",
      "Fetching event 2023inpri\n",
      "Fetching event 2023inwla\n",
      "Fetching event 2023iscmp\n",
      "Fetching event 2023isde1\n",
      "Fetching event 2023isde2\n",
      "Fetching event 2023isde3\n",
      "Fetching event 2023isde4\n",
      "Fetching event 2023ksla\n",
      "Fetching event 2023lake\n",
      "Fetching event 2023mabos\n",
      "Fetching event 2023mabri\n",
      "Fetching event 2023marea\n",
      "Fetching event 2023mawne\n",
      "Fetching event 2023mawor\n",
      "Fetching event 2023mdbet\n",
      "Fetching event 2023mdtim\n",
      "Fetching event 2023mibel\n",
      "Fetching event 2023micmp\n",
      "Fetching event 2023midet\n",
      "Fetching event 2023midtr\n",
      "Fetching event 2023miesc\n",
      "Fetching event 2023mifor\n",
      "Fetching event 2023mijac\n",
      "Fetching event 2023mike2\n",
      "Fetching event 2023miken\n",
      "Fetching event 2023miket\n",
      "Fetching event 2023mikk\n",
      "Fetching event 2023mikk2\n",
      "Fetching event 2023mila2\n",
      "Fetching event 2023milak\n",
      "Fetching event 2023milan\n",
      "Fetching event 2023miliv\n",
      "Fetching event 2023milsu\n",
      "Fetching event 2023mimcc\n",
      "Fetching event 2023mimid\n",
      "Fetching event 2023mimil\n",
      "Fetching event 2023mimus\n",
      "Fetching event 2023misal\n",
      "Fetching event 2023misjo\n",
      "Fetching event 2023mista\n",
      "Fetching event 2023mitr2\n",
      "Fetching event 2023mitry\n",
      "Fetching event 2023mitvc\n",
      "Fetching event 2023miwmi\n",
      "Fetching event 2023mndu\n",
      "Fetching event 2023mndu2\n",
      "Fetching event 2023mnkk\n",
      "Fetching event 2023mnmi\n",
      "Fetching event 2023mnmi2\n",
      "Fetching event 2023mnwz\n",
      "Fetching event 2023mokc\n",
      "Fetching event 2023mose\n",
      "Fetching event 2023mosl\n",
      "Fetching event 2023mrcmp\n",
      "Fetching event 2023mslr\n",
      "Fetching event 2023mxmo\n",
      "Fetching event 2023mxpu\n",
      "Fetching event 2023mxto\n",
      "Fetching event 2023ncash\n",
      "Fetching event 2023nccmp\n",
      "Fetching event 2023ncjoh\n",
      "Fetching event 2023ncmec\n",
      "Fetching event 2023ncpem\n",
      "Fetching event 2023ncwak\n",
      "Fetching event 2023ndgf\n",
      "Fetching event 2023necmp\n",
      "Fetching event 2023nhdur\n",
      "Fetching event 2023nhgrs\n",
      "Fetching event 2023njfla\n",
      "Fetching event 2023njrob\n",
      "Fetching event 2023njski\n",
      "Fetching event 2023njtab\n",
      "Fetching event 2023njwas\n",
      "Fetching event 2023nvlv\n",
      "Fetching event 2023nyli\n",
      "Fetching event 2023nyli2\n",
      "Fetching event 2023nyny\n",
      "Fetching event 2023nyro\n",
      "Fetching event 2023nyrra\n",
      "Fetching event 2023nytr\n",
      "Fetching event 2023nywz\n",
      "Fetching event 2023ohcl\n",
      "Fetching event 2023ohmv\n",
      "Fetching event 2023okok\n",
      "Fetching event 2023oktu\n",
      "Fetching event 2023onbar\n",
      "Fetching event 2023oncmp\n",
      "Fetching event 2023onham\n",
      "Fetching event 2023onlon\n",
      "Fetching event 2023onnew\n",
      "Fetching event 2023onnob\n",
      "Fetching event 2023ontor\n",
      "Fetching event 2023onwat\n",
      "Fetching event 2023onwin\n",
      "Fetching event 2023orore\n",
      "Fetching event 2023orsal\n",
      "Fetching event 2023orwil\n",
      "Fetching event 2023paben\n",
      "Fetching event 2023paca\n",
      "Fetching event 2023pahat\n",
      "Fetching event 2023paphi\n",
      "Fetching event 2023pncmp\n",
      "Fetching event 2023qcmo\n",
      "Fetching event 2023rinsc\n",
      "Fetching event 2023scand\n",
      "Fetching event 2023schar\n",
      "Fetching event 2023tnkn\n",
      "Fetching event 2023tuhc\n",
      "Fetching event 2023tuis\n",
      "Fetching event 2023tuis2\n",
      "Fetching event 2023tuis3\n",
      "Fetching event 2023txama\n",
      "Fetching event 2023txbel\n",
      "Fetching event 2023txcha\n",
      "Fetching event 2023txcle\n",
      "Fetching event 2023txcmp\n",
      "Fetching event 2023txdal\n",
      "Fetching event 2023txfor\n",
      "Fetching event 2023txhou\n",
      "Fetching event 2023txsan\n",
      "Fetching event 2023txwac\n",
      "Fetching event 2023utwv\n",
      "Fetching event 2023vaale\n",
      "Fetching event 2023vabla\n",
      "Fetching event 2023vagle\n",
      "Fetching event 2023vapor\n",
      "Fetching event 2023waahs\n",
      "Fetching event 2023wabon\n",
      "Fetching event 2023wasam\n",
      "Fetching event 2023wasno\n",
      "Fetching event 2023wayak\n",
      "Fetching event 2023week0\n",
      "Fetching event 2023wila\n",
      "Fetching event 2023wimi\n",
      "Fetching event 2023wisr\n",
      "Fetching event 2023wiwz\n",
      "Fetching event 2023zhha\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import pickle\n",
    "#import time\n",
    "import sys\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('..')\n",
    "import swagger_client as v3client\n",
    "from swagger_client.rest import ApiException\n",
    "\n",
    "# If you fetch_matches best to set reset=True or you may miss some events.\n",
    "fetch_matches = True\n",
    "reset = True\n",
    "year = 2023\n",
    "\n",
    "if fetch_matches:\n",
    "    from fetchMatches import fetch_all_matches\n",
    "    # This will save to matches_{year}.pkl\n",
    "    fetch_all_matches(year, reset=reset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the matches\n",
    "\n",
    "filename = f'matches_{year}.pkl'\n",
    "matches = []\n",
    "with open(filename, 'rb') as f:\n",
    "    matches = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2023orore',\n",
       " '2023orsal',\n",
       " '2023orwil',\n",
       " '2023pncmp',\n",
       " '2023waahs',\n",
       " '2023wabon',\n",
       " '2023wasam',\n",
       " '2023wasno',\n",
       " '2023wayak']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [m for m in matches['events'] if m.address and 'Spokane' in m.address]\n",
    "#[m for m in matches['events'] if 'pnc' in m.key]\n",
    "pnw_district = [m.key for m in matches['events'] if m.district and m.district.abbreviation=='pnw']\n",
    "pnw_district"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the matches to completed matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 matches\n",
      "PNW Teams: ['frc1294', 'frc1318', 'frc1359', 'frc1425', 'frc1432', 'frc1540', 'frc1595', 'frc1778', 'frc1899', 'frc1983', 'frc2046', 'frc2097', 'frc2147', 'frc2374', 'frc2412', 'frc2471', 'frc2521', 'frc2522', 'frc2550', 'frc2557', 'frc2635', 'frc2733', 'frc2811', 'frc2898', 'frc2903', 'frc2907', 'frc2910', 'frc2915', 'frc2926', 'frc2928', 'frc2929', 'frc2930', 'frc2976', 'frc2980', 'frc2990', 'frc3024', 'frc3049', 'frc3070', 'frc3218', 'frc3219', 'frc3268', 'frc3393', 'frc3588', 'frc360', 'frc3636', 'frc3663', 'frc3673', 'frc3674', 'frc3681', 'frc3711', 'frc3712', 'frc3786', 'frc3826', 'frc3876', 'frc4043', 'frc4060', 'frc4061', 'frc4089', 'frc4104', 'frc4125', 'frc4127', 'frc4131', 'frc4173', 'frc4180', 'frc4450', 'frc4469', 'frc4488', 'frc4512', 'frc4513', 'frc4579', 'frc4662', 'frc4681', 'frc4682', 'frc4692', 'frc488', 'frc4911', 'frc4915', 'frc4918', 'frc492', 'frc4980', 'frc5295', 'frc5468', 'frc5588', 'frc568', 'frc5683', 'frc5827', 'frc5920', 'frc5937', 'frc5941', 'frc5970', 'frc5975', 'frc6076', 'frc6343', 'frc6350', 'frc6443', 'frc6465', 'frc6696', 'frc6831', 'frc6845', 'frc7034', 'frc7461', 'frc753', 'frc7627', 'frc8032', 'frc8051', 'frc8248', 'frc8302', 'frc8303', 'frc8386', 'frc847', 'frc8532', 'frc8896', 'frc9023', 'frc9036', 'frc948', 'frc949', 'frc955', 'frc957', 'frc997']\n"
     ]
    }
   ],
   "source": [
    "non_empty = [k for k in matches['matches'].keys() if len(matches['matches'][k])>0]\n",
    "data = [m for k in matches['matches'] for m in matches['matches'][k]]\n",
    "data = [m for m in data if m.winning_alliance!='' and m.score_breakdown is not None]\n",
    "print(f'Found {len(data)} matches')\n",
    "\n",
    "pnw_teams = set()\n",
    "for m in [m for m in data if m.event_key in pnw_district]:\n",
    "    for t in m.alliances.red.team_keys:\n",
    "        pnw_teams.add(t)\n",
    "    for t in m.alliances.blue.team_keys:\n",
    "        pnw_teams.add(t)\n",
    "    \n",
    "pnw_teams = list(sorted(pnw_teams))\n",
    "print(f'PNW Teams: {pnw_teams}')\n",
    "#red = [x for m in data for x in m.alliances.red.team_keys]\n",
    "#blue = [x for m in data for x in m.alliances.blue.team_keys]\n",
    "#from collections import Counter\n",
    "#Counter(red+blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'f': 237, 'qm': 8012, 'sf': 1351})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finals, quarterfinales, qualifiers, semifinals\n",
    "Counter([x.comp_level for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll only train based on qualifier matches\n",
    "\n",
    "qualifiers = [x for x in data if x.comp_level=='qm'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create aggregate team statistics for all teams, and a separate set for PNW teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from featurization import addMatch\n",
    "\n",
    "teamAggregates = {}\n",
    "pnwAggregates  = {}\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "for m in qualifiers:    \n",
    "    for t in m.alliances.red.team_keys:\n",
    "        addMatch(t, m, teamAggregates)\n",
    "        if m.event_key in pnw_district:\n",
    "            addMatch(t, m, pnwAggregates)\n",
    "    for t in m.alliances.blue.team_keys:\n",
    "        addMatch(t,m, teamAggregates)\n",
    "        if m.event_key in pnw_district:\n",
    "            addMatch(t, m, pnwAggregates)\n",
    "        \n",
    "# normalize the aggregates -- TODO: move all this code to featurization.py\n",
    "def normalize(aggregates):\n",
    "    for t in aggregates:\n",
    "        for k in aggregates[t]:\n",
    "            if k=='totalMatches':\n",
    "                continue\n",
    "            aggregates[t][k]/=aggregates[t]['totalMatches']\n",
    "        aggregates[t]['totalMatches'] = 1.0\n",
    "\n",
    "normalize(teamAggregates)\n",
    "normalize(pnwAggregates)\n",
    "\n",
    "with open('teamStats_2023.pkl','wb') as f:\n",
    "    pickle.dump(teamAggregates,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'2023orore': 84,\n",
       "         '2023orsal': 78,\n",
       "         '2023orwil': 69,\n",
       "         '2023wabon': 76,\n",
       "         '2023wasam': 50,\n",
       "         '2023wasno': 83,\n",
       "         '2023wayak': 69})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([m.event_key for m in data if m.event_key in pnw_district])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have statistics for every team.  We can use this to generate features for every match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 9600/9600 [00:08<00:00, 1189.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from featurization import featurizeMatch, invertMatch\n",
    "features = []\n",
    "\n",
    "for m in tqdm(data):\n",
    "    f = featurizeMatch(m, teamAggregates)\n",
    "    features.append(f)\n",
    "    #features.append(invertMatch(f))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9600"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8012 training examples and 1588 test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# create train and test sets\n",
    "train = []\n",
    "trainY = []\n",
    "test = []\n",
    "testY = []\n",
    "\n",
    "for m in features:    \n",
    "    if 'event' not in m:\n",
    "        print(m)\n",
    "    event = m['event']\n",
    "    comp_level = m['comp_level']\n",
    "    del m['event']\n",
    "    del m['comp_level']\n",
    "    \n",
    "    label = m['label']\n",
    "    del m['label']\n",
    "    \n",
    "    # Train on qualifiers. Test on everything else.\n",
    "    if comp_level!='qm':\n",
    "        test.append(m)\n",
    "        testY.append(label)\n",
    "    else:\n",
    "        train.append(m)\n",
    "        trainY.append(label)\n",
    "        \n",
    "vectorizer = DictVectorizer()\n",
    "trainX = vectorizer.fit_transform(train)\n",
    "testX = vectorizer.transform(test)\n",
    "\n",
    "print('{} training examples and {} test'.format(len(train),len(test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6cd102934db3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mforest_predictions\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mforest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 387\u001b[1;33m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m    388\u001b[0m                              \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'threads'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    167\u001b[0m                                                         indices=indices)\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    896\u001b[0m         \"\"\"\n\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 898\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0, min_samples_split=3)  \n",
    "classifier.fit(trainX,trainY)\n",
    "forest_predictions= classifier.predict(testX)\n",
    "forest_scores = classifier.predict_proba(testX)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#np.sum(np.abs(scores-Ytest))\n",
    "print('accuracy: {}'.format(accuracy_score(testY, forest_predictions)))\n",
    "#list(zip(forest_scores[:,1],testY))\n",
    "\n",
    "# Save the model\n",
    "model_fn = 'model_2023_forest.pkl'\n",
    "with open(model_fn, 'wb') as outF:\n",
    "    pickle.dump((vectorizer,classifier), outF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the feature importances. They tell us how useful a specific feature is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN = 20\n",
    "importances = classifier.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in classifier.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1][:topN]\n",
    "names = vectorizer.feature_names_\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "#for f in range(trainX.shape[1]):\n",
    "#    print(\"%d. %s (%f)\" % (f + 1, names[indices[f]], importances[indices[f]]))\n",
    "colors = [names[indices[f]].split('_')[0] for f in range(topN)]\n",
    "labels = [names[indices[f]].replace('Count','').replace('Points','').replace('red','r').replace('blue','b') for f in range(topN)]\n",
    "# Plot the feature importances of the forest\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(topN), importances[indices],\n",
    "       color=colors, \n",
    "        #yerr=std[indices], \n",
    "        align=\"center\")\n",
    "plt.xticks(range(topN), labels, rotation='vertical', fontsize='large')\n",
    "    \n",
    "plt.xlim([-1, topN])\n",
    "plt.subplots_adjust(bottom=0.5)\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(dictionary, key):\n",
    "    teams = [t for t in dictionary]\n",
    "    values = [dictionary[t][key] for t in dictionary]\n",
    "    ranks = sorted(range(len(values)), key=lambda x: values[x])\n",
    "    return dict([(teams[ranks[i]], i*100/len(values)) for i in range(len(ranks))])    \n",
    "\n",
    "raw = dict([(k, percentile(teamAggregates,k)) for k in teamAggregates['frc1153']])\n",
    "#stats = dict([(k,percentile(teamAggregates,k)['frc1153']) for k in teamAggregates['frc1153']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell enables comparisons between two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "objects = [k for k in raw]\n",
    "y_pos = np.arange(len(objects))\n",
    "#performance = [[raw[k]['frc492'],raw[k]['frc2910']] for k in stats]\n",
    "#performance\n",
    "t1 = 'frc1153'\n",
    "t2 = 'frc238'\n",
    "plt.figure()\n",
    "plt.bar(y_pos, [raw[k][t1] for k in raw], alpha=0.5, width=0.25)\n",
    "plt.bar(y_pos+0.25, [raw[k][t2] for k in raw], alpha=0.5, width=0.25)\n",
    "plt.xticks(y_pos, objects, rotation=90, fontsize='x-small')\n",
    "plt.subplots_adjust(bottom=0.5)\n",
    "plt.ylabel('Percentile')\n",
    "plt.title('Stats summary')\n",
    "plt.legend([t1,t2])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far our best score at predicting the districts is about 70% using RandomForests.  Next time we can explore hyperparameter tuning and also predicting which alliances would have been the best ones for us to join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next steps: for a given event we want to decide how to prioritize alliance choices.  Suppose we have all the data to date, as well as all the qualifier data for the event. Who should we choose as partners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize alliances for {target_id} at {event} on second pick:\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from featurization import featurizeAlliances\n",
    "from itertools import combinations\n",
    "\n",
    "event = '2023wasam'\n",
    "target_id = 492\n",
    "teams = set([t for x in \\\n",
    "    [m.alliances.red.team_keys + m.alliances.blue.team_keys for m in matches['matches'][event]] \\\n",
    "        for t in x])\n",
    "print(f'There are {len(teams)} teams at this event')\n",
    "\n",
    "model_fn = 'model_2023_forest.pkl'\n",
    "with open(model_fn, 'rb') as inF:\n",
    "    vectorizer, model = pickle.load(inF)\n",
    "\n",
    "# wasno\n",
    "taken_wasno = [\n",
    "    #2910, 2930, 7627, 488, 4911, # 4915, 1318, 2522 -- for 4911 on their first pick.\n",
    "    #2910, 4131, 6443, 1595, 2811, 5920, 5468, 492, 2147, 1318, 955, 3711, 7461, 4061, 4980\n",
    "]\n",
    "\n",
    "\n",
    "taken = list(map(lambda x: f'frc{x}', taken_wasno))\n",
    "\n",
    "# set to just ['frc492'] if you're ranking pairs\n",
    "target = [f'frc{target_id}']\n",
    "# target = ['frc492', 'frc1899']\n",
    "\n",
    "# If you are ranking pairs\n",
    "if len(target)==1:\n",
    "    partners = [[x,y] for x in teams if x!=target for y in teams if y!=target if x<y and x not in taken and y not in taken]\n",
    "else:\n",
    "    partners = [[x] for x in teams if x not in taken]\n",
    "results = {}\n",
    "features = []\n",
    "alliances = []\n",
    "trials = 500 \n",
    "\n",
    "# iterate through all the potential pairs of partners. \n",
    "# For each pair, we sample {trials} opponent alliances and assess whether we think they will win.\n",
    "for p in tqdm(partners): \n",
    "    red = target + p  \n",
    "    candidates = [x for x in teams if x not in red]\n",
    "    \n",
    "    # Run trials sampling blue alliances from the remaining teams.\n",
    "    # Here we're sampling any possible alliance, except the members of red.\n",
    "    # We just run {trials} samples because a typical event has about 34 teams, which would yield \n",
    "    # more than 5000 alliances, requiring more than 2 million match predictions in total\n",
    "    \n",
    "    for m in range(trials):\n",
    "        blue = random.sample(candidates, 3)\n",
    "        f = featurizeAlliances(teamAggregates, red, blue)\n",
    "        features.append(f)\n",
    "        alliances.append([red,blue])\n",
    "\n",
    "# run all the simulated matches through the model\n",
    "print(f\"Running {len(features)} predictions\")\n",
    "scores = model.predict_proba(vectorizer.transform(features))\n",
    "results = {}\n",
    "for (p,_), score in zip(alliances, scores): \n",
    "    p = tuple(p)\n",
    "    if p not in results:\n",
    "        results[p] = 0\n",
    "    results[p] += score[1]    \n",
    "\n",
    "\n",
    "for r in list(sorted(results, key=lambda x: results[x], reverse=True))[:100]:\n",
    "    print(r, results[r]*100/trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Districts\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Districts event key is '2022pncmp': update this on Friday night\n",
    "#event = '2022pncmp'\n",
    "event = '2023wayak'\n",
    "\n",
    "# Fetch the event rankings so far.\n",
    "from fetchMatches import fetch_event_rankings\n",
    "rankings = fetch_event_rankings(event)\n",
    "\n",
    "print([(r.rank, r.team_key) for r in rankings.rankings])\n",
    "teams = [r.team_key for r in rankings.rankings]\n",
    "\n",
    "rank_492 = [r.rank for r in rankings.rankings if r.team_key==f'frc{target_id}'][0]\n",
    "prior_taken = teams[:rank_492]\n",
    "print(prior_taken)\n",
    "teams_ahead = rank_492-1\n",
    "all_taken = teams[:rank_492+teams_ahead]\n",
    "print(all_taken)\n",
    "\n",
    "rankings_dict = dict([(r.team_key, r.rank) for r in rankings.rankings])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell continues with the event key set above.\n",
    "\n",
    "teams = set([t for x in \\\n",
    "    [m.alliances.red.team_keys + m.alliances.blue.team_keys for m in matches['matches'][event]] \\\n",
    "        for t in x])\n",
    "print(teams)\n",
    "model_fn = 'model_2023_forest.pkl'\n",
    "with open(model_fn, 'rb') as inF:\n",
    "    vectorizer, model = pickle.load(inF)\n",
    "\n",
    "# Set to include only 492 when we just want to rank all the potential alliances.\n",
    "taken = [\n",
    "    target_id\n",
    "]\n",
    "\n",
    "\n",
    "taken = list(map(lambda x: f'frc{x}', taken))\n",
    "\n",
    "# set to just ['frc492'] if you're ranking pairs, ['frc492', 'first choice partner'] if you want to rank second choices.\n",
    "target = [f'frc{target_id}']\n",
    "# target = ['frc492', 'frc1899']\n",
    "\n",
    "# If you are ranking pairs\n",
    "if len(target)==1:\n",
    "    partners = [[x,y] for x in teams if x!=target for y in teams if y!=target if x<y and x not in taken and y not in taken]\n",
    "else:\n",
    "    partners = [[x] for x in teams if x not in taken]\n",
    "results = {}\n",
    "features = []\n",
    "alliances = []\n",
    "trials = 1000\n",
    "for p in tqdm(partners): \n",
    "    red = target + p  \n",
    "    candidates = [x for x in teams if x not in red]\n",
    "    \n",
    "    for m in range(trials):\n",
    "        # Here we're sampling any possible alliance, except the members of red.    \n",
    "        blue = random.sample(candidates, 3)\n",
    "        f = featurizeAlliances(teamAggregates, red, blue)\n",
    "        features.append(f)\n",
    "        alliances.append([red,blue])\n",
    "\n",
    "# run all the simulated matches through the model\n",
    "scores = model.predict_proba(vectorizer.transform(features))\n",
    "results = {}\n",
    "for (p,_), score in zip(alliances, scores): \n",
    "    p = tuple(p)\n",
    "    if p not in results:\n",
    "        results[p] = 0\n",
    "    results[p] += score[1]    \n",
    "\n",
    "for p in results:\n",
    "    results[p] = results[p] * 100 / trials\n",
    "\n",
    "for r in list(sorted(results, key=lambda x: results[x], reverse=True))[:100]:\n",
    "    print(r, results[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('alliance_rankings.csv', 'w', encoding='utf-8') as outF:\n",
    "    outF.write('a1,a2,a3,p(win),rank1,rank2,rank3\\n')\n",
    "    for (a1,a2,a3) in list(sorted(results, key=lambda x: results[x], reverse=True)):\n",
    "        outF.write('{},{},{},{},{},{},{}\\n'.format(a1,a2,a3,results[(a1,a2,a3)], rankings_dict[a1], rankings_dict[a2], rankings_dict[a3]))\n",
    "\n",
    "ranks = {}\n",
    "for r in results:\n",
    "    for a in r[1:]:\n",
    "        if a not in ranks:\n",
    "            ranks[a] = 0\n",
    "        ranks[a]+=results[r]\n",
    "with open('team_rankings.csv', 'w', encoding='utf-8') as outF:\n",
    "    outF.write('team,score,pnw_rank\\n')\n",
    "    for a in sorted(ranks, key=lambda x: ranks[x], reverse=True):\n",
    "        outF.write('{},{},{}\\n'.format(a,ranks[a], rankings_dict[a]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One more using only districts stats\n",
    "# This cell continues with the event key set above.\n",
    "\n",
    "teams = set([t for x in \\\n",
    "    [m.alliances.red.team_keys + m.alliances.blue.team_keys for m in matches['matches'][event]] \\\n",
    "        for t in x])\n",
    "print(teams)\n",
    "model_fn = 'model_2023_forest.pkl'\n",
    "with open(model_fn, 'rb') as inF:\n",
    "    vectorizer, model = pickle.load(inF)\n",
    "\n",
    "# Set to include only 492 when we just want to rank all the potential alliances.\n",
    "taken = [\n",
    "    target_id\n",
    "]\n",
    "\n",
    "\n",
    "taken = list(map(lambda x: f'frc{x}', taken))\n",
    "\n",
    "# set to just ['frc492'] if you're ranking pairs, ['frc492', 'first choice partner'] if you want to rank second choices.\n",
    "target = [f'frc{target_id}']\n",
    "# target = ['frc492', 'frc1899']\n",
    "\n",
    "# If you are ranking pairs\n",
    "if len(target)==1:\n",
    "    partners = [[x,y] for x in teams if x!=target for y in teams if y!=target if x<y and x not in taken and y not in taken]\n",
    "else:\n",
    "    partners = [[x] for x in teams if x not in taken]\n",
    "results = {}\n",
    "features = []\n",
    "alliances = []\n",
    "trials = 1000\n",
    "for p in tqdm(partners): \n",
    "    red = target + p  \n",
    "    candidates = [x for x in teams if x not in red]\n",
    "    \n",
    "    for m in range(trials):\n",
    "        # Here we're sampling any possible alliance, except the members of red.    \n",
    "        blue = random.sample(candidates, 3)\n",
    "        f = featurizeAlliances(red, blue, pnwAggregates)\n",
    "        features.append(f)\n",
    "        alliances.append([red,blue])\n",
    "\n",
    "# run all the simulated matches through the model\n",
    "scores = model.predict_proba(vectorizer.transform(features))\n",
    "results = {}\n",
    "for (p,_), score in zip(alliances, scores): \n",
    "    p = tuple(p)\n",
    "    if p not in results:\n",
    "        results[p] = 0\n",
    "    results[p] += score[1]    \n",
    "\n",
    "for p in results:\n",
    "    results[p] = results[p] * 100 / trials\n",
    "\n",
    "for r in list(sorted(results, key=lambda x: results[x], reverse=True))[:100]:\n",
    "    print(r, results[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('pnw_alliance_rankings.csv', 'w', encoding='utf-8') as outF:\n",
    "    outF.write('a1,a2,a3,p(win),rank1,rank2,rank3\\n')\n",
    "    for (a1,a2,a3) in list(sorted(results, key=lambda x: results[x], reverse=True)):\n",
    "        outF.write('{},{},{},{},{},{},{}\\n'.format(a1,a2,a3,results[(a1,a2,a3)], rankings_dict[a1], rankings_dict[a2], rankings_dict[a3]))\n",
    "\n",
    "ranks = {}\n",
    "for r in results:\n",
    "    for a in r[1:]:\n",
    "        if a not in ranks:\n",
    "            ranks[a] = 0\n",
    "        ranks[a]+=results[r]\n",
    "with open('pnw_team_rankings.csv', 'w', encoding='utf-8') as outF:\n",
    "    outF.write('team,score,pnw_rank\\n')\n",
    "    for a in sorted(ranks, key=lambda x: ranks[x], reverse=True):\n",
    "        outF.write('{},{},{}\\n'.format(a,ranks[a], rankings_dict[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brackets\n",
    "import random \n",
    "model_fn = 'model_2023_forest.pkl'\n",
    "with open(model_fn, 'rb') as inF:\n",
    "    vectorizer, model = pickle.load(inF)\n",
    "\n",
    "wins = Counter()\n",
    "\n",
    "trials = 1000\n",
    "for t in tqdm(range(trials)):\n",
    "    # TODO: download from TBA\n",
    "    brackets = list(map(lambda x: list(map(lambda y: f'frc{y}', x)),\n",
    "        [\n",
    "            (4911, 2910, 3218),\n",
    "            (2990, 955, 360),\n",
    "            (5827, 2147, 2557),\n",
    "            (4089, 1595, 3663),\n",
    "            (2046, 2976, 488),\n",
    "            (7034, 997, 1899),\n",
    "            (4488, 2471, 2522),\n",
    "            (3636, 2930, 3674)\n",
    "        ]))\n",
    "\n",
    "    while len(brackets)>1:\n",
    "        alliances = []\n",
    "        features = []\n",
    "        for x in range(0,len(brackets),2):\n",
    "            red = brackets[x]\n",
    "            blue = brackets[x+1]\n",
    "            #print(red,blue)\n",
    "            f = featurizeAlliances(red, blue, aggregates=teamAggregates)       \n",
    "            features.append(f)\n",
    "            alliances.append([red,blue])\n",
    "\n",
    "        # run all the simulated matches through the model\n",
    "        scores = model.predict_proba(vectorizer.transform(features))\n",
    "        results = {}\n",
    "        next_round = []\n",
    "        for (r,b), score in zip(alliances, scores): \n",
    "            #print(r,b,score)\n",
    "            #if score[1]>score[0]:\n",
    "            if random.random()<score[1]:\n",
    "                next_round.append(r)\n",
    "            else:\n",
    "                next_round.append(b)\n",
    "        brackets = next_round\n",
    "        #print(brackets)\n",
    "    wins[tuple(brackets[0])]+=1\n",
    "for x in sorted(wins, reverse=True, key=lambda x: wins[x]):\n",
    "    print(f'{tuple(map(lambda y: y[3:], x))} {wins[x]/10}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
