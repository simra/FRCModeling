{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We'll start from the models we trained last time and try to optimize their parameters.  First load and train the model as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data into a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#import time\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "sys.path.append('..')\n",
    "import swagger_client as v3client\n",
    "from swagger_client.rest import ApiException\n",
    "\n",
    "filename = '../matches.pkl'\n",
    "matches = []\n",
    "with open(filename, 'rb') as f:\n",
    "    matches = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "teamAggregates = {}\n",
    "\n",
    "def addMatch(team, m):    \n",
    "    if team not in teamAggregates:       \n",
    "        # initialize an empty record for the team.\n",
    "        teamAggregates[team]= {\n",
    "            'totalMatches':0, \n",
    "            'autoPoints':0, \n",
    "            'cargoPoints':0, \n",
    "            'completeRocketRankingPoints':0, \n",
    "            'completedRocketCount':0, \n",
    "            'habLevel1Count':0, \n",
    "            'habLevel2Count':0, \n",
    "            'habLevel3Count':0,             \n",
    "            'foulCount':0, \n",
    "            'foulPoints':0, \n",
    "            'rocketPanelCount':0, \n",
    "            'rocketCargoCount':0, \n",
    "            'bayPanelCount':0, \n",
    "            'bayCargoCount':0, \n",
    "            'habLineCount':0, \n",
    "            'habDockingRankingPoints':0, \n",
    "            'habClimbPoints':0, \n",
    "            'hatchPanelPoints':0, \n",
    "            'rankingPoints':0, \n",
    "            'sandStormBonusPoints':0, \n",
    "            'techFoulCount':0, \n",
    "            'teleopPoints':0, \n",
    "            'totalPoints':0, \n",
    "            'winCount':0\n",
    "        }\n",
    "\n",
    "    alliance = 'blue' if team in m.alliances.blue.team_keys else 'red'\n",
    "    points = m.score_breakdown[alliance]\n",
    "    summary = teamAggregates[team]\n",
    "    # update all of the fields.\n",
    "    summary['totalMatches']+=1    \n",
    "    summary['autoPoints']+=points['autoPoints']\n",
    "    summary['cargoPoints']+=points['cargoPoints'] \n",
    "    summary['completeRocketRankingPoints']+=int(points['completeRocketRankingPoint']) \n",
    "    summary['completedRocketCount']+=int(points['completedRocketFar'])+int(points['completedRocketNear'])\n",
    "    for r in [1,2,3]:\n",
    "        l = points['endgameRobot'+str(r)]\n",
    "        if l=='HabLevel1':\n",
    "            summary['habLevel1Count']+=1\n",
    "        elif l=='HabLevel2':\n",
    "            summary['habLevel2Count']+=1\n",
    "        elif l=='HabLevel3':\n",
    "            summary['habLevel3Count']+=1\n",
    "        h = points['habLineRobot'+str(r)]\n",
    "        if h=='CrossedHabLineInSandstorm':\n",
    "            summary['habLineCount']+=1\n",
    "\n",
    "    summary['foulCount']+=points['foulCount']\n",
    "    summary['foulPoints']+=points['foulPoints']\n",
    "    \n",
    "    # Rocket cargo and panel positions\n",
    "    for l in ['low','mid','top']:\n",
    "            for s in ['Left','Right']:\n",
    "                for n in ['Near','Far']:\n",
    "                    r = l+s+'Rocket'+n  #e.g. lowLeftRocketNear\n",
    "                    if points[r]=='Panel':\n",
    "                        summary['rocketPanelCount']+=1\n",
    "                    if points[r]=='PanelAndCargo':\n",
    "                        summary['rocketPanelCount']+=1\n",
    "                        summary['rocketCargoCount']+=1\n",
    "    # bays 1:8                 \n",
    "    for b in range(1,9): \n",
    "        bay = 'bay'+str(b)\n",
    "        if points[bay]=='Panel':\n",
    "            summary['bayPanelCount']+=1\n",
    "        if points[bay]=='PanelAndCargo':\n",
    "            summary['bayPanelCount']+=1\n",
    "            summary['bayCargoCount']+=1\n",
    "            \n",
    "    summary['habDockingRankingPoints']+=int(points['habDockingRankingPoint'])\n",
    "    summary['habClimbPoints']+=points['habClimbPoints'] \n",
    "    summary['hatchPanelPoints']+=points['hatchPanelPoints']\n",
    "    summary['rankingPoints']+=points['rp']\n",
    "    summary['sandStormBonusPoints']+=points['sandStormBonusPoints']\n",
    "    summary['techFoulCount']+=points['techFoulCount']\n",
    "    summary['teleopPoints']+=points['teleopPoints']\n",
    "    summary['totalPoints']+=points['totalPoints']\n",
    "    summary['winCount']+=int(m.winning_alliance==alliance)\n",
    "\n",
    "\n",
    "for m in matches:\n",
    "    # only aggregate statistics for regional matches- skip the districts or we're cheating.\n",
    "    if m.event_key=='2019pncmp':\n",
    "        continue\n",
    "    for t in m.alliances.red.team_keys:\n",
    "        addMatch(t,m)\n",
    "    for t in m.alliances.blue.team_keys:\n",
    "        addMatch(t,m)\n",
    "        \n",
    "# normalize the aggregates\n",
    "for t in teamAggregates:\n",
    "    for k in ['autoPoints', 'cargoPoints', 'completeRocketRankingPoints', 'completedRocketCount', 'habLevel1Count', 'habLevel2Count', 'habLevel3Count', 'foulCount', 'foulPoints', 'rocketPanelCount', 'rocketCargoCount', 'bayPanelCount', 'bayCargoCount', 'habLineCount', 'habDockingRankingPoints', 'habClimbPoints', 'hatchPanelPoints', 'rankingPoints', 'sandStormBonusPoints', 'techFoulCount', 'teleopPoints', 'totalPoints', 'winCount']:\n",
    "        teamAggregates[t][k]/=teamAggregates[t]['totalMatches']\n",
    "\n",
    "with open('../teamStats.pkl','wb') as f:\n",
    "    pickle.dump(teamAggregates,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have statistics for every team.  We can use this to generate features for every match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def featurizeMatch(m):\n",
    "    match_features = { 'red_missingCount':0, 'blue_missingCount': 0 }\n",
    "    count=0    \n",
    "    allKeys = set()\n",
    "    for t in m.alliances.red.team_keys:\n",
    "        if t not in teamAggregates:\n",
    "            match_features['red_missingCount']+=1\n",
    "            continue\n",
    "        for k in teamAggregates[t]:\n",
    "            key = 'red_'+k;\n",
    "            if key not in match_features:\n",
    "                match_features[key]=0\n",
    "            match_features[key]+=teamAggregates[t][k]\n",
    "            allKeys.add(key)\n",
    "        count+=1\n",
    "    # compute the average\n",
    "    for k in allKeys:\n",
    "        match_features[k]/=count\n",
    "    count=0\n",
    "    allKeys=set()\n",
    "    for t in m.alliances.blue.team_keys:\n",
    "        if t not in teamAggregates:\n",
    "            match_features['blue_missingCount']+=1\n",
    "            continue\n",
    "        for k in teamAggregates[t]:\n",
    "            key = 'blue_'+k;\n",
    "            if key not in match_features:\n",
    "                match_features[key]=0\n",
    "            match_features[key]+=teamAggregates[t][k]\n",
    "            allKeys.add(key)\n",
    "        count+=1\n",
    "    # compute the average\n",
    "    for k in allKeys:\n",
    "        match_features[k]/=count\n",
    "    match_features['event']=m.event_key\n",
    "    match_features['label']=int(m.winning_alliance=='red')    \n",
    "    return match_features\n",
    "\n",
    "features = []\n",
    "\n",
    "for m in matches:\n",
    "    features.append(featurizeMatch(m))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# create train and test sets\n",
    "train = []\n",
    "trainY = []\n",
    "test = []\n",
    "testY = []\n",
    "\n",
    "for m in features:\n",
    "    if 'event' not in m:\n",
    "        print(m)\n",
    "    event = m['event']\n",
    "    label = m['label']\n",
    "    del m['event']\n",
    "    del m['label']\n",
    "    if event == '2019pncmp':\n",
    "        test.append(m)\n",
    "        testY.append(label)\n",
    "    else:\n",
    "        train.append(m)\n",
    "        trainY.append(label)\n",
    "        \n",
    "vectorizer = DictVectorizer()\n",
    "trainX = vectorizer.fit_transform(train)\n",
    "testX = vectorizer.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7062937062937062"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0, min_samples_split=3)  \n",
    "classifier.fit(trainX,trainY)\n",
    "forest_predictions= classifier.predict(testX)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#np.sum(np.abs(scores-Ytest))\n",
    "accuracy_score(testY, forest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the possible parameters we could tune. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 0,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a basic grid search over some of these parameters: let's vary min_samples_leaf, min_samples_split, max_depth, and n_estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_params = {'max_depth': [None, 3, 10], 'min_samples_leaf':[1,3,5], 'min_samples_split':[3,5,10], 'n_estimators':[1,8,32,100,200]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7202797202797203\n",
      "Grid: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "classifier=RandomForestClassifier()\n",
    "best_score = 0\n",
    "best_g=None\n",
    "\n",
    "for g in ParameterGrid(grid_params):\n",
    "    classifier.set_params(**g)\n",
    "    classifier.fit(trainX,trainY)\n",
    "    forest_predictions= classifier.predict(testX)\n",
    "    score = accuracy_score(testY, forest_predictions)\n",
    "    if score>best_score:\n",
    "        best_score=score\n",
    "        best_g = g\n",
    "\n",
    "print(\"Accuracy: {}\".format(best_score))\n",
    "print(\"Grid:\", best_g)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
