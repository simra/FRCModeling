{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Prediction cheated by mixing the past with the future.  In this example we predict the winners of district matches using the regionals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training data into a pandas data frame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_auburn = pd.read_csv('../event_features_2019waahs.txt', sep='\\t', header=None, names=['Label','RedAlliance','BlueAlliance'])\n",
    "train_glacier = pd.read_csv('../event_features_2019wasno.txt', sep='\\t', header=None, names=['Label','RedAlliance','BlueAlliance'])\n",
    "\n",
    "test_districts = pd.read_csv('../event_features_2019pncmp.txt', sep='\\t', header=None, names=['Label','RedAlliance','BlueAlliance'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>RedAlliance</th>\n",
       "      <th>BlueAlliance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>frc2990 frc2046 frc4579</td>\n",
       "      <td>frc4911 frc4089 frc6503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>frc2990 frc2046 frc4579</td>\n",
       "      <td>frc4911 frc4089 frc2929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>frc2990 frc2046 frc4579</td>\n",
       "      <td>frc3049 frc5937 frc3219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>frc2990 frc2046 frc4579</td>\n",
       "      <td>frc3049 frc5937 frc3219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>frc2907 frc1318 frc2926</td>\n",
       "      <td>frc360 frc3574 frc3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>frc2907 frc1318 frc2926</td>\n",
       "      <td>frc360 frc3574 frc3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>frc2907 frc1318 frc2926</td>\n",
       "      <td>frc360 frc3574 frc3876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>frc492 frc4918 frc7118</td>\n",
       "      <td>frc948 frc4131 frc3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>frc492 frc4918 frc7118</td>\n",
       "      <td>frc948 frc4131 frc3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>frc4911 frc4089 frc6503</td>\n",
       "      <td>frc2097 frc6350 frc2927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label              RedAlliance             BlueAlliance\n",
       "0      1  frc2990 frc2046 frc4579  frc4911 frc4089 frc6503\n",
       "1      1  frc2990 frc2046 frc4579  frc4911 frc4089 frc2929\n",
       "2      1  frc2990 frc2046 frc4579  frc3049 frc5937 frc3219\n",
       "3      1  frc2990 frc2046 frc4579  frc3049 frc5937 frc3219\n",
       "4      1  frc2907 frc1318 frc2926   frc360 frc3574 frc3876\n",
       "5      0  frc2907 frc1318 frc2926   frc360 frc3574 frc3876\n",
       "6      0  frc2907 frc1318 frc2926   frc360 frc3574 frc3876\n",
       "7      0   frc492 frc4918 frc7118   frc948 frc4131 frc3070\n",
       "8      0   frc492 frc4918 frc7118   frc948 frc4131 frc3070\n",
       "9      1  frc4911 frc4089 frc6503  frc2097 frc6350 frc2927"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_auburn[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can leverage some concepts from https://stackabuse.com/text-classification-with-python-and-scikit-learn/ to build our model.  The basic idea is to use the team names as features.  Suppose frc492 is a really strong team- when it appears in the RedAlliance column it will add some weight to the probability that Red wins, and vice-versa if it appear in the BlueAlliance column.  So we want to build a predictor that figures out how much it matters when frc492 appears in a column (and the same for any other team)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1500, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# two count vectorizers. This transforms the alliance lists into vector encodings\n",
    "redVectorizer = CountVectorizer(max_features=1500, min_df=1, max_df=1.0, stop_words=None)  \n",
    "blueVectorizer = CountVectorizer(max_features=1500, min_df=1, max_df=1.0, stop_words=None)  \n",
    "\n",
    "ct = ColumnTransformer([('RedFeatures',redVectorizer,'RedAlliance'), ('BlueFeatures',blueVectorizer,'BlueAlliance')])\n",
    "\n",
    "# shuffle the data first\n",
    "train = pd.concat([train_auburn,train_glacier])\n",
    "\n",
    "\n",
    "#train = train.sample(frac=1.0)\n",
    "\n",
    "# produce the training features and labels.\n",
    "X = ct.fit_transform(train)\n",
    "y = train.Label\n",
    "\n",
    "Xtest = ct.transform(test_districts)\n",
    "Ytest = test_districts.Label\n",
    "\n",
    "#print(X.size, Xtest.size)\n",
    "X[0,:].todense()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data in a state where we can start to build models. First we'll try a basic random forest with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=3,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0, min_samples_split=3)  \n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6223776223776224"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run four-fold cross-validation\n",
    "classifier.fit(X,y)\n",
    "predictions= classifier.predict(Xtest)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#np.sum(np.abs(scores-Ytest))\n",
    "accuracy_score(Ytest, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's also try logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6573426573426573"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "classifier.fit(X,y)\n",
    "predictions= classifier.predict(Xtest)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#np.sum(np.abs(scores-Ytest))\n",
    "accuracy_score(Ytest, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5868103 , -0.04314238, -0.14691068,  0.13190829,  0.49756141,\n",
       "         0.80239966,  0.80182232, -0.21024997,  0.45816607,  0.22811268,\n",
       "        -0.71924245,  0.38870251,  0.85145406,  0.04643039, -0.28996806,\n",
       "         0.04281725,  0.18891051,  0.64006504,  0.02125542, -0.12703109,\n",
       "         0.52500084,  0.27548982,  0.03995078, -0.53126367, -0.68487465,\n",
       "        -0.14415331, -0.37514581,  0.0493587 , -0.12728641,  0.22305092,\n",
       "        -0.10970571, -0.21694156, -0.00287245,  0.12197748,  0.13150219,\n",
       "         0.30289102,  0.08674119,  0.29617266, -0.67136896,  0.01088446,\n",
       "         0.06897651, -0.06176445,  0.01632013, -0.48190099,  0.27050696,\n",
       "         0.66949304, -0.56328806,  0.17033902, -0.78288639, -0.28234112,\n",
       "         0.69705285, -0.33378606,  0.30730376, -0.08304786, -0.21712732,\n",
       "        -0.61501923, -0.38685469, -0.2523031 ,  0.08527722,  0.61808883,\n",
       "         0.11850904, -0.27100749, -0.42266106, -0.72064782, -0.28970764,\n",
       "         0.14206805, -0.74989159,  0.04814039,  0.09838541, -0.44496461,\n",
       "        -0.04909803, -0.0156155 , -0.18306433, -0.6255953 , -0.05545081,\n",
       "        -0.27554998, -0.25206212,  0.03199148, -0.00612762, -0.2761044 ,\n",
       "         0.00747213, -0.13590158, -0.36002433,  0.39133149, -0.38298787,\n",
       "         0.0703124 ,  0.41180398, -0.67838767,  0.58716265,  0.29720511,\n",
       "        -0.1785689 ,  0.46234514, -0.06414916, -0.14611699, -0.12295636,\n",
       "        -0.46367521, -0.0675196 , -0.64500086,  0.41606893, -0.10138907,\n",
       "         0.75002758, -0.13970607, -0.13669   , -0.13400088, -0.40682557,\n",
       "         0.14442459, -0.00477458,  0.01516686,  0.11222385,  0.00386826,\n",
       "         0.52769363, -0.22720665,  0.28955957,  0.35263095,  0.30927848,\n",
       "         0.14834946, -0.36221085, -0.6762919 ,  0.16087173, -0.11651533,\n",
       "         0.02443562, -0.50969716,  0.39691628, -0.01380201,  0.34393103,\n",
       "         0.22127907,  0.00448285, -0.37127544,  0.67400826,  0.37654446,\n",
       "         0.19030486,  0.47995184, -0.03738729,  0.31750506]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6363636363636364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "classifier = RidgeClassifier()\n",
    "classifier.fit(X,y)\n",
    "predictions= classifier.predict(Xtest)\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "#np.sum(np.abs(scores-Ytest))\n",
    "accuracy_score(Ytest, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
